{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oyDbv0ZQEi0"
   },
   "source": [
    "\n",
    "# EE 461P: Data Science Principles\n",
    "# Assignment 3\n",
    "## Total points: 65\n",
    "## Due: Tuesday, March 10th, submitted via Canvas by 11:59 pm\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Your partner needs to be from the same section. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTEID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group. If you do change, let the TA know. \n",
    "\n",
    "Please ensure that the notebook you have uploaded on Canvas is the correct one, you could download the notebook from Canvas to double check that you have submitted the correct version on your notebook.\n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2KPQqiuQO0v"
   },
   "source": [
    "### Name(s)\n",
    "1. Alex Li (al45532)\n",
    "2. Zander Tedjo (zbt86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WLbp0FO_5NOl"
   },
   "source": [
    "# Question 1 - Regression using MLP (30 pts)\n",
    "\n",
    "We will use the same dataset used in Homework 1 and try to design a MLP model for the same. \n",
    "\n",
    "Use the following code below to import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dt1dyCWO5RmM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "random_num = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mz49kWbD5Tmq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(0)\n",
    "X = df.drop(['SalePrice'], axis=1)\n",
    "Y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oM3TM2g85XPH"
   },
   "source": [
    "For the below questions, use seed for random number as 42. You will need this seed for all instances of `train_test_split()` and `MLPRegressor()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWK6Y1Eh5Zvq"
   },
   "source": [
    "a. **(4 pts)** Using Multi-layer Perceptron regressor, fit a regression model with `alpha=0` on all the feature variables using the entire dataset. Report the total of number of weights present in the weight matrix (obtained using `model.coefs_`) and evaluate the model using mean squared error (MSE). An example is shown in [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor).\n",
    "\n",
    "b. **(6 pts)** Split the data into a training set and a test set, using the train_test_split with `test_size = 0.25` and `random_state = 42`. Fit an MLP using the training set with `alpha=0` and `max_iter=1000`. Evaluate the trained model using the training set and the test set, respectively. Compare the two MSE values thus obtained. Give one reason behind the change in loss value.\n",
    "\n",
    "c. **(5 pts)** Calculate the pearson correlation matrix of the independent variables in the training set. Show the correlation matrix as a [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) without annotations. Report the two features that are most positively and negatively correlated (excluding the same features) from the correlation matrix. [Sample code](https://stackoverflow.com/a/41453817)\n",
    "\n",
    "d. **(6 pts)** Run MLPRegressor like part (a) but this time, use different values for alpha, which is the L2 penalty (regularization term) parameter. Take at least 10 values of alpha within the range of [0, 0.001]. Plot the MSE for various values of alpha. Explain the value of alpha that gives the minimum MSE. What does this mean?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1a\n",
      "\n",
      "First layer has  19  weights\n",
      "Second layer has  100  weights\n",
      "Total number of weights is  119\n",
      "\n",
      "MSE  2116661777.4075637\n"
     ]
    }
   ],
   "source": [
    "# Answer 1a\n",
    "print(\"Answer 1a\\n\")\n",
    "\n",
    "model = MLPRegressor(random_state=42, alpha=0, max_iter=1000)\n",
    "model.fit(X, Y)\n",
    "coefs = model.coefs_\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "mse = mean_squared_error(Y, y_pred)\n",
    "\n",
    "\n",
    "print(\"First layer has \", len(coefs[0]), \" weights\")\n",
    "print(\"Second layer has \", len(coefs[1]), \" weights\")\n",
    "print(\"Total number of weights is \", (len(coefs[0]) + len(coefs[1])))\n",
    "\n",
    "print()\n",
    "print(\"MSE \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1b\n",
      "\n",
      "MSE train  2200124929.2119737\n",
      "MSE test  1866181108.1068006\n",
      "\n",
      "The MSE train value increased slightly because it had less data to train on\n",
      "The MSE test value improved because the model overfitted less\n"
     ]
    }
   ],
   "source": [
    "# Answer 1b\n",
    "print(\"Answer 1b\\n\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = MLPRegressor(random_state=42, alpha=0, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"MSE train \", mse_train)\n",
    "print(\"MSE test \", mse_test)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"The MSE train value increased slightly because it had less data to train on\")\n",
    "print(\"The MSE test value improved because the model overfitted less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1c\n",
      "\n",
      "Most positive correlation\n",
      "GarageArea GarageCars 0.8824754142814603\n",
      "\n",
      "Most negative correlation\n",
      "1stFlrSF MSSubClass -0.2517583518783804\n"
     ]
    }
   ],
   "source": [
    "# Answer 1c\n",
    "print(\"Answer 1c\\n\")\n",
    "import seaborn as sns\n",
    "\n",
    "corr = X.corr()\n",
    "ax = sns.heatmap(corr)\n",
    "\n",
    "max_corr = -1000\n",
    "min_corr = 1000\n",
    "max_features = []\n",
    "min_features = []\n",
    "\n",
    "labels = corr.columns.values\n",
    "\n",
    "for r in range(0, corr.shape[0]):\n",
    "    for c in range(0, r):\n",
    "        val = corr.iloc[r,c]\n",
    "        if(val > max_corr):\n",
    "            max_corr = val\n",
    "            max_features = [r,c]\n",
    "        if(val < min_corr):\n",
    "            min_corr = val\n",
    "            min_features = [r,c]\n",
    "\n",
    "print(\"Most positive correlation\")\n",
    "print(labels[max_features[0]],labels[max_features[1]], max_corr)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Most negative correlation\")\n",
    "print(labels[min_features[0]],labels[min_features[1]], min_corr)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1d\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min MSE occurs when alpha is 0.0002\n",
      "When alpha is 0.0002, there is a good amount of regularization and limit on complexity, so the model will resist overfitting and be closer to the compelxity of the data.\n"
     ]
    }
   ],
   "source": [
    "# Answer 1d\n",
    "print(\"Answer 1d\\n\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "alphas = np.linspace(0, 0.001, 11)\n",
    "mse_list = []\n",
    "\n",
    "for a in alphas:\n",
    "    model = MLPRegressor(random_state=42, alpha=a, max_iter=1000)\n",
    "    model.fit(X, Y)\n",
    "\n",
    "    y_pred = model.predict(X)\n",
    "    mse = mean_squared_error(Y, y_pred)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "plt.plot(alphas, mse_list)\n",
    "plt.xlabel('alphas')\n",
    "plt.ylabel('mse')\n",
    "plt.show()\n",
    "\n",
    "print(\"Min MSE occurs when alpha is 0.0002\")\n",
    "print(\"When alpha is 0.0002, there is a good amount of regularization and limit on complexity, so the model will resist overfitting and be closer to the compelxity of the data.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JkUDUJkf4wzt"
   },
   "source": [
    "# Question 2 - Decision Tree Classifier (20 pts)\n",
    "**Customer Eligibility for Deposits**\n",
    "\n",
    "Predict if a customer will subscribe (yes/no) to a fixed deposit, by building a classification model using Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ubGiNvt40ty"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from io import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "S_1II-W841OG",
    "outputId": "dc7e0f5e-fda9-40c4-e7e7-b31032a9afdc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2343</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>45</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>1270</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2476</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>184</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         job  marital  education default  balance housing loan  contact  \\\n",
       "0   59      admin.  married  secondary      no     2343     yes   no  unknown   \n",
       "1   56      admin.  married  secondary      no       45      no   no  unknown   \n",
       "2   41  technician  married  secondary      no     1270     yes   no  unknown   \n",
       "3   55    services  married  secondary      no     2476     yes   no  unknown   \n",
       "4   54      admin.  married   tertiary      no      184      no   no  unknown   \n",
       "\n",
       "   day month  duration  campaign  pdays  previous poutcome deposit  \n",
       "0    5   may      1042         1     -1         0  unknown     yes  \n",
       "1    5   may      1467         1     -1         0  unknown     yes  \n",
       "2    5   may      1389         1     -1         0  unknown     yes  \n",
       "3    5   may       579         1     -1         0  unknown     yes  \n",
       "4    5   may       673         2     -1         0  unknown     yes  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data file\n",
    "bank=pd.read_csv('bank.csv')\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mlI7BEw2448s"
   },
   "source": [
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "\n",
    "3 - marital : marital status (categorical: 'divorced','married','single'; note: 'divorced' means divorced or widowed)\n",
    "\n",
    "4 - education (categorical: 'primary', 'secondary','tertiary')\n",
    "\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "\n",
    "6 - balance: account balance\n",
    "\n",
    "7 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "8 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "# related with the last contact of the current campaign:\n",
    "9 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "\n",
    "10 - day_of_month : 1,2....31\n",
    "\n",
    "11 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "\n",
    "12 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "\n",
    "14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 10000 means client was not previously contacted)\n",
    "\n",
    "15 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "\n",
    "16 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','other','success','unknown')\n",
    "\n",
    "Output variable (desired target):\n",
    "17 - y - has the client subscribed a term deposit? (binary: 'yes','no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XurVpT-ssmRI"
   },
   "source": [
    "**All the pre-processing is done where the categorical variables are converted to numeric values and unnecessary columns are dropped.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xu3KThGNssC8"
   },
   "outputs": [],
   "source": [
    "# Make a copy for parsing\n",
    "bank_data = bank.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "deB1ykE4ss4z"
   },
   "outputs": [],
   "source": [
    "# Drop 'contact', as every participant has been contacted. \n",
    "bank_data.drop('contact', axis=1, inplace=True)\n",
    "# Drop 'month' and 'day' as they don't have any intrinsic meaning\n",
    "bank_data.drop('month', axis=1, inplace=True)\n",
    "bank_data.drop('day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxUjyUzJ45aM"
   },
   "outputs": [],
   "source": [
    "#Convert categorical values to numeric values\n",
    "# values for \"default\" : yes/no\n",
    "bank_data[\"default\"]\n",
    "bank_data['default_cat'] = bank_data['default'].map( {'yes':1, 'no':0} )\n",
    "bank_data.drop('default', axis=1,inplace = True)\n",
    "# values for \"housing\" : yes/no\n",
    "bank_data[\"housing_cat\"]=bank_data['housing'].map({'yes':1, 'no':0})\n",
    "bank_data.drop('housing', axis=1,inplace = True)\n",
    "# values for \"loan\" : yes/no\n",
    "bank_data[\"loan_cat\"] = bank_data['loan'].map({'yes':1, 'no':0})\n",
    "bank_data.drop('loan', axis=1, inplace=True)\n",
    "# values for \"deposit\" : yes/no\n",
    "bank_data[\"deposit_cat\"] = bank_data['deposit'].map({'yes':1, 'no':0})\n",
    "bank_data.drop('deposit', axis=1, inplace=True)\n",
    "\n",
    "# Convert categorical variables to dummies\n",
    "bank_data = pd.get_dummies(data=bank_data, columns = ['job', 'marital', 'education', 'poutcome'], \\\n",
    "                                   prefix = ['job', 'marital', 'education', 'poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9uf-31waszkH"
   },
   "outputs": [],
   "source": [
    "# Convert p_days to a probability value\n",
    "bank_data['recent_pdays'] = np.where(bank_data['pdays'], 1/bank_data.pdays, 1/bank_data.pdays)\n",
    "# Drop 'pdays'\n",
    "bank_data.drop('pdays', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "zDbBqOAJ5D17",
    "outputId": "58b08a5c-374c-4f72-f531-56327d3cd802"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>default_cat</th>\n",
       "      <th>housing_cat</th>\n",
       "      <th>loan_cat</th>\n",
       "      <th>deposit_cat</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "      <th>recent_pdays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2343</td>\n",
       "      <td>1042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>1467</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1270</td>\n",
       "      <td>1389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>2476</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>184</td>\n",
       "      <td>673</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  balance  duration  campaign  previous  default_cat  housing_cat  \\\n",
       "0   59     2343      1042         1         0            0            1   \n",
       "1   56       45      1467         1         0            0            0   \n",
       "2   41     1270      1389         1         0            0            1   \n",
       "3   55     2476       579         1         0            0            1   \n",
       "4   54      184       673         2         0            0            0   \n",
       "\n",
       "   loan_cat  deposit_cat  job_admin.      ...       marital_single  \\\n",
       "0         0            1           1      ...                    0   \n",
       "1         0            1           1      ...                    0   \n",
       "2         0            1           0      ...                    0   \n",
       "3         0            1           0      ...                    0   \n",
       "4         0            1           1      ...                    0   \n",
       "\n",
       "   education_primary  education_secondary  education_tertiary  \\\n",
       "0                  0                    1                   0   \n",
       "1                  0                    1                   0   \n",
       "2                  0                    1                   0   \n",
       "3                  0                    1                   0   \n",
       "4                  0                    0                   1   \n",
       "\n",
       "   education_unknown  poutcome_failure  poutcome_other  poutcome_success  \\\n",
       "0                  0                 0               0                 0   \n",
       "1                  0                 0               0                 0   \n",
       "2                  0                 0               0                 0   \n",
       "3                  0                 0               0                 0   \n",
       "4                  0                 0               0                 0   \n",
       "\n",
       "   poutcome_unknown  recent_pdays  \n",
       "0                 1          -1.0  \n",
       "1                 1          -1.0  \n",
       "2                 1          -1.0  \n",
       "3                 1          -1.0  \n",
       "4                 1          -1.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "trQaS_P85EbR"
   },
   "outputs": [],
   "source": [
    "# Splitting the data into training and test data with 80:20 ratio with random_state=50.\n",
    "# Building the data model\n",
    "# Train-Test split: 20% test data\n",
    "X = bank_data.drop('deposit_cat', 1)\n",
    "Y = bank_data.deposit_cat\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTZH9d3K5Hvp"
   },
   "source": [
    "a. **(8 pts)** Build a decision tree with depths 2,3,5,10 and max depth using gini and entropy criterion; report the train and test error.\n",
    "\n",
    "b. **(2 pts)** Explain how the train and test accuracy vary as we increase the depth of the tree.\n",
    "\n",
    "c. **(4 pts)** List the most important features for the tree with depth=2 and criterion=gini and plot the tree.\n",
    "\n",
    "d. **(6 pts)** Report the accuracy and AUC for the test data and plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2a\n",
      "\n",
      "Depth 2\n",
      "Gini prediction:\n",
      "train error 0.7285250307985217\n",
      "test error 0.7268248992386923\n",
      "\n",
      "Entropy prediction:\n",
      "train error 0.7119498264083324\n",
      "test error 0.7089117778772951\n",
      "\n",
      "\n",
      "Depth 3\n",
      "Gini prediction:\n",
      "train error 0.770411020271027\n",
      "test error 0.7572772055530677\n",
      "\n",
      "Entropy prediction:\n",
      "train error 0.7623474073244484\n",
      "test error 0.7568293775190327\n",
      "\n",
      "\n",
      "Depth 5\n",
      "Gini prediction:\n",
      "train error 0.7976257139657297\n",
      "test error 0.7760859829825347\n",
      "\n",
      "Entropy prediction:\n",
      "train error 0.7998656064508903\n",
      "test error 0.7783251231527094\n",
      "\n",
      "\n",
      "Depth 10\n",
      "Gini prediction:\n",
      "train error 0.8634785530294545\n",
      "test error 0.7859381997313032\n",
      "\n",
      "Entropy prediction:\n",
      "train error 0.8500391981184903\n",
      "test error 0.7890729959695477\n",
      "\n",
      "\n",
      "Depth None\n",
      "Gini prediction:\n",
      "train error 1.0\n",
      "test error 0.7348858038513211\n",
      "\n",
      "Entropy prediction:\n",
      "train error 1.0\n",
      "test error 0.7196596506941334\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Answer 2a\n",
    "print(\"Answer 2a\\n\")\n",
    "\n",
    "depths = [2,3,5,10, None]\n",
    "\n",
    "for d in depths:\n",
    "    print(\"Depth\", d)\n",
    "    \n",
    "    # Gini\n",
    "    clf = DecisionTreeClassifier(criterion = \"gini\", max_depth = d, random_state = 0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    train_error = clf.score(X_train, Y_train)\n",
    "    test_error = clf.score(X_test, Y_test)\n",
    "\n",
    "    print(\"Gini prediction:\")\n",
    "    print(\"train error\", train_error)\n",
    "    print(\"test error\", test_error)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    # Entropy\n",
    "    clf = DecisionTreeClassifier(criterion = \"entropy\", max_depth = d, random_state = 0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "\n",
    "    train_error = clf.score(X_train, Y_train)\n",
    "    test_error = clf.score(X_test, Y_test)\n",
    "\n",
    "    print(\"Entropy prediction:\")\n",
    "    print(\"train error\", train_error)\n",
    "    print(\"test error\", test_error)\n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 2b\n",
    "As the depth increases, so does the accuracy of the prediction. It appears that after a max_depth of 3 the results do not change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2c\n",
      "\n",
      "[0.         0.         0.84930612 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.15069388\n",
      " 0.         0.        ]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'sklearn.tree._tree.Tree' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-9f233717af0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\export.py\u001b[0m in \u001b[0;36mplot_tree\u001b[1;34m(decision_tree, max_depth, feature_names, class_names, label, filled, impurity, node_ids, proportion, rotate, rounded, precision, ax, fontsize)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mproportion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproportion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrotate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrounded\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         precision=precision, fontsize=fontsize)\n\u001b[1;32m--> 178\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mexporter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\export.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(self, decision_tree, ax)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis_off\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         my_tree = self._make_tree(0, decision_tree.tree_,\n\u001b[0m\u001b[0;32m    572\u001b[0m                                   decision_tree.criterion)\n\u001b[0;32m    573\u001b[0m         \u001b[0mdraw_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuchheim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'sklearn.tree._tree.Tree' object has no attribute 'tree_'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Answer 2c\n",
    "print(\"Answer 2c\\n\")\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion = \"gini\", max_depth = 2, random_state = 0)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "feature_importances = clf.feature_importances_\n",
    "print(feature_importances)\n",
    "\n",
    "model_tree = clf.tree_\n",
    "tree.plot_tree(model_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 2d\n",
    "print(\"Answer 2d\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucVu7A2k4jSP"
   },
   "source": [
    "# Question 3 - Bayes Decision Theory (10pts)\n",
    "\n",
    "a. (2pts) Explain what you understand by class-conditional likelihood, class priors, and posterior probability of a class given an input, and the relationship between them. Please define all symbols and equations used explicitly.\n",
    "\n",
    "b. (5pts) Suppose you want to learn a binary classifier to predict whether or not a customer will buy a TV. The class label is 1 if the customer buys and 2 if he/she does not. For each customer, you are given two features, $x_1$ is the salary per hour and $x_2$ is the age. Assume that the class conditional distribution $p(x_1,x_2|C)$ is Gaussian for both classes. The mean salary and age of the people who do buy a TV is 30 and 39 respectively and that of those who don't is 16 and 20. Also assume that covariances of these two groups are given by $I$ (for \"buy class\") and $4I$ respectively, where $I$ is the identity matrix. Further, your sales data suggests that only 1 in 5 people actually buy a TV. Mathematically derive the (optimal) Bayes decision boundary for this problem.\n",
    "\n",
    "c. (3pts) Write a script to sample 100 customers from class (C = 1) and correspondingly from class 2, under the assumed distribution and the estimated parameters and create a scatter plot. Plot the decision boundary you obtained in  part (b) on the same plot. (You can hardcode the co-efficient values for the deicision boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A\n",
    "Class conditional likelihood - Probability of the value of a conditional variable given a dependent state of nature\n",
    "\n",
    "Class priors - an estimate of the probability that randomly sampling an instance from a population will yield the given class\n",
    "\n",
    "Posterior probability - The probability of a class given input features\n",
    "\n",
    "posterior probability = (Class conditional likelihood)(Class priors)/probability density \n",
    "$$P(w_j|x) = \\frac{p(x|w_j)P(w_j)}{p(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B\n",
    "\n",
    "First we determine the prior probabilities $P(C_1)$ and $P(C_2)$\n",
    "\n",
    "Since 1 in 5 people actually buy a TV, then \n",
    "\n",
    "$$P(C_1) = 0.2$$ \n",
    "$$P(C_2) = 0.8$$\n",
    "\n",
    "\n",
    "Next we determine the class conditional likelihoods\n",
    "\n",
    "$$p(x_1|C_1) = $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjVL_Zta4oNi"
   },
   "source": [
    "\n",
    "# Question 4 - Asymmetric Cost Function (5pts)\n",
    "\n",
    "Consider the loss matrix below specified for a certain 3-class problem:\n",
    "\n",
    "\n",
    "|     .  |  . | $C_1$ |   $C_2$  | $C_3$ |\n",
    "|-------|-------|-------|:--------:|-------|\n",
    "| .    | $C_1$ | 3     |     4    | 5     |\n",
    "| Truth | $C_2$ | 8     |     0    | 2     |\n",
    "| .     | $C_3$ | -6    |     0    | -8    |\n",
    "|  .   |   .   |   .   | Decision |       |\n",
    "\n",
    "\n",
    "\n",
    "For what range of values of $P(C_1|x)$ will you declare x to belong to Class 1 if your goal is to minimize the expected loss rather than minimizing misclassification error? To make this problem simpler, assume that  $P(C_2|x) = P(C_3|x)$ for all x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw3_final_questions",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
